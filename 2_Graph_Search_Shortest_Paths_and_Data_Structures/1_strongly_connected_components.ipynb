{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file `1_SCC.txt` contains the edges of a directed graph. Vertices are labeled as positive integers from 1 to 875714. Every row indicates an edge, the vertex label in first column is the tail and the vertex label in second column is the head (recall the graph is directed, and the edges are directed from the first column vertex to the second column vertex). So for example, the 11th row looks like: \"2 47646\". This just means that the vertex with label 2 has an outgoing edge to the vertex with label 47646.\n",
    "\n",
    "Your task is to code up the algorithm from the video lectures for computing strongly connected components (SCCs), and to run this algorithm on the given graph.\n",
    "\n",
    "Output Format: You should output the sizes of the 5 largest SCCs in the given graph, in decreasing order of sizes, separated by commas (avoid any spaces). So if your algorithm computes the sizes of the five largest SCCs to be 500, 400, 300, 200 and 100, then your answer should be \"500,400,300,200,100\" (without the quotes). If your algorithm finds less than 5 SCCs, then write 0 for the remaining terms. Thus, if your algorithm computes only 3 SCCs whose sizes are 400, 300, and 100, then your answer should be \"400,300,100,0,0\" (without the quotes).  (Note also that your answer should not have any spaces in it.)\n",
    "\n",
    "WARNING: Because of the size of the graph you may have to manage memory carefully. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kosaraju's Two-Pass Algorithm: \n",
    "# Given directed graph G\n",
    "# Let G_rev = G with all arcs reversed\n",
    "# run DFS-Loop on G_rev to compute \"magical\" ordering of nodes\n",
    "# Let f(v) = \"finishing time\" of each vertex v\n",
    "# run DFS-Loop on G processing nodes in decreasing order of finishing times to discover the SCCs one-by-one\n",
    "\n",
    "# DFS-Loop (graph G)\n",
    "# global variable t = 0 [# of nodes processed so far] - for finishing times in 1st pass\n",
    "# global variable s = NULL [current source vertex] - for leaders in 2nd pass\n",
    "# Assume nodes labelled 1 to n\n",
    "# for i=n...1:\n",
    "#     if i not yet explored\n",
    "#         s := i\n",
    "#         DFS(G,i)\n",
    "\n",
    "# DFS (graph G, node i)\n",
    "# mark i explored (for rest of DFS-Loop)\n",
    "# set leader(i) := node s\n",
    "# for each (i,j) in G:\n",
    "#     if j not yet explored:\n",
    "#         DFS(G,j)\n",
    "# t++\n",
    "# set f(i) := t (ith finishing time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# while writing the code, I encountered the maximum recursion depth exceeded error \n",
    "# max recursion error protects us against a stack overflow. This is when the pointer in a stack exceeds \n",
    "# the stack bound. Without this error, our program would try to use more memory space than was available.\n",
    "# print recursion depth limit\n",
    "import sys\n",
    "sys.getrecursionlimit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can override the default recursion limit Python sets\n",
    "# you should be careful when you use this method because it may cause a stack overflow \n",
    "# depending on the resources available to the Python interpreter.\n",
    "#DFS_Loop(tails = heads, heads = tails, node_labels = list(range(874931, 874930, -1)), N = N)\n",
    "# got to len of nodes_explored:  6,656 with default recursive length of 3000\n",
    "# got to len of nodes_explored: 27,770 with resursive length 12000\n",
    "# got to len of nodes_explored: 51,184 with resursive length 20000\n",
    "# got to len of nodes_explored: 142,751 with resursive length 40000 but kernel died\n",
    "# for one node i = 874931, 615,722 is the length of nodes explored from that node \n",
    "# and the iterative algorithm took more than a day\n",
    "sys.setrecursionlimit(40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getrecursionlimit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFS_recursive(tails, heads, i):\n",
    "    \"\"\"\n",
    "    Depth-first search recursive function.\n",
    "    \n",
    "    Input parameters:\n",
    "    tails -- list of tail nodes in the input directed graph\n",
    "    heads -- list of head nodes in the input directed graph\n",
    "    i -- vertex i from which to start DFS\n",
    "    \n",
    "    Output:\n",
    "    f(i) -- ith node finishing time\n",
    "    \n",
    "    \"\"\"\n",
    "    # global declaration is required is we are changing t value inside the function\n",
    "    global t\n",
    "    # mark i explored (for rest of DFS-Loop)\n",
    "    nodes_explored.append(i)\n",
    "\n",
    "    # set leader(i) := node s\n",
    "    # leaders is indexed 0 to N-1\n",
    "    # so for node N, assign its leader to N-1 position in the numpy array\n",
    "    leaders[i-1] = s\n",
    "    \n",
    "    # indices where tail node is i\n",
    "    ii = np.where(tails == i)[0]\n",
    "\n",
    "    # tail nodes from i to j\n",
    "    jj = heads[ii]\n",
    "    \n",
    "    # for each (i,j) in G:\n",
    "    for arc in jj:\n",
    "        # if j not yet explored:\n",
    "        if arc not in nodes_explored:\n",
    "            # DFS(G,j)\n",
    "            DFS(tails, heads, arc)\n",
    "            \n",
    "    # t++\n",
    "    t += 1\n",
    "    # set f(i) := t (ith finishing time)\n",
    "    f[i-1] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another way to deal with recursion depth limit is\n",
    "# to rewrite the function as a iterative "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFS_iterative(tails, heads, i):\n",
    "    \"\"\"\n",
    "    Depth-first search function replacing recursion with a loop\n",
    "    to avoid stack overflow errors and maximum recusion depth limits\n",
    "    set by Python because of memory limitation. Choose this function\n",
    "    when dealing with a large graph.\n",
    "    \n",
    "    Input parameters:\n",
    "    tails -- list of tail nodes in the input directed graph\n",
    "    heads -- list of head nodes in the input directed graph\n",
    "    i -- vertex i from which to start DFS\n",
    "    \n",
    "    Output:\n",
    "    f(i) -- ith node finishing time\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    # global declaration is required as we are changing t value inside the function\n",
    "    global t\n",
    " \n",
    "    current_nodes = [i]\n",
    "    \n",
    "    # collect all nodes that DFS would recurse on to assign f values\n",
    "    nodes_to_assign = []\n",
    "    \n",
    "    while bool(current_nodes) :\n",
    "        # pop last item from list\n",
    "        i = current_nodes.pop()\n",
    "        \n",
    "        if i not in nodes_explored:\n",
    "            nodes_explored.append(i)\n",
    "            print('number of nodes explored: ', len(nodes_explored))\n",
    "\n",
    "            nodes_to_assign.append(i) \n",
    "            \n",
    "            leaders[i-1] = s\n",
    "            ii = np.where(tails == i)[0]\n",
    "            if ii.size != 0:\n",
    "                jj = heads[ii]\n",
    "                for arc in jj:\n",
    "                    current_nodes.append(arc)\n",
    "\n",
    "\n",
    "    for n in reversed(nodes_to_assign):\n",
    "        t += 1\n",
    "        f[n-1] = t\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DFS_Loop(tails, heads, node_labels, N):\n",
    "    \"\"\"\n",
    "    Depth-first search loop.\n",
    "    \n",
    "    Input parameters:\n",
    "    tails -- list of tail nodes in the input directed graph\n",
    "    heads -- list of head nodes in the input directed graph\n",
    "    node_labels -- order of nodes to process\n",
    "    N -- number of nodes in the input graph\n",
    "    \"\"\"\n",
    "    global s\n",
    "   \n",
    "    # global variable t = 0 [# of nodes processed so far] - for finishing times in 1st pass\n",
    "    # global variable s = NULL [current source vertex] - for leaders in 2nd pass\n",
    "    # Assume nodes labelled 1 to n\n",
    "    # for i=n...1:\n",
    "    for i in node_labels:\n",
    "        print('i in DFS_Loop', i)\n",
    "        # if i not yet explored\n",
    "        if i not in nodes_explored:\n",
    "            # s := i\n",
    "            s = i\n",
    "            # DFS(G,i)\n",
    "            #DFS_recursive(tails, heads, i)\n",
    "            DFS_iterative(tails, heads, i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Kosarajus(input_file, N):\n",
    "    \"\"\"\n",
    "    Kosaraju's Two-Pass Algorithm.\n",
    "    \n",
    "    Input parameters:\n",
    "    input_file -- a text file containing two columns for tails and heads of the vertices\n",
    "    N -- number of nodes in the given graph\n",
    "    \n",
    "    Output:\n",
    "    dictionary sorted by decreasing order of SCC's in a given graph\n",
    "    \"\"\"\n",
    "    global nodes_explored, leaders, t, f\n",
    "    \n",
    "    # number of vertices\n",
    "    N = N\n",
    "    \n",
    "    # read in input graph\n",
    "    with open(input_file) as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # these two arrays represend the input directed graph G\n",
    "    tails = np.empty(len(lines), dtype=np.int)\n",
    "    heads = np.empty(len(lines), dtype=np.int)\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        tails[i] = line.split(' ')[0]\n",
    "        heads[i] = line.split(' ')[1]\n",
    "        \n",
    "    nodes_explored = []\n",
    "    \n",
    "    # ith node leader\n",
    "    leaders = np.empty(N, dtype=np.int)\n",
    "\n",
    "    # ith finishing time \n",
    "    f = np.zeros(N, dtype=np.int)\n",
    "    \n",
    "    # number of nodes processed so far\n",
    "    t = 0\n",
    "    # current source vertex\n",
    "    s = np.NaN\n",
    "    \n",
    "    # first pass of DFS_Loop\n",
    "    # Let G_rev = G with all arcs reversed\n",
    "    # run DFS-Loop on G_rev to compute \"magical\" ordering of nodes\n",
    "    DFS_Loop(tails = heads, heads = tails, node_labels = list(range(N, 0, -1)), N = N)\n",
    "    \n",
    "    # reset \n",
    "    nodes_explored = []\n",
    "    # ith node leader\n",
    "    leaders = np.empty(N, dtype=np.int)\n",
    "    # number of nodes processed so far\n",
    "    t = 0\n",
    "    # current source vertex\n",
    "    s = np.NaN\n",
    "    \n",
    "    # relabel the nodes based on finishing time f\n",
    "    tails_second_pass = np.empty(len(tails), dtype=np.int) \n",
    "    heads_second_pass = np.empty(len(heads), dtype=np.int) \n",
    "    \n",
    "    for ff in f:\n",
    "        # iterate over the finishing times \n",
    "        ii = np.where(tails == ff)[0]\n",
    "        tails_second_pass[ii] = f[ff-1] \n",
    "        ii = np.where(heads == ff)[0]\n",
    "        heads_second_pass[ii] = f[ff-1]\n",
    "       \n",
    "    # second pass of DFS_Loop\n",
    "    # Let f(v) = \"finishing time\" of each vertex v\n",
    "    # run DFS-Loop on G processing nodes in decreasing order of finishing times to discover the SCCs one-by-one\n",
    "    DFS_Loop(tails = tails_second_pass, heads = heads_second_pass, node_labels=list(range(N, 0, -1)), N = N)\n",
    "    \n",
    "    # output the sizes of the 5 largest SCCs in the given graph, in decreasing order of sizes\n",
    "    scc = pd.DataFrame(leaders, columns = [\"x\"]).groupby('x').size().to_dict()\n",
    "    result = {k: v for k, v in sorted(scc.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for '1_SCC.txt' graph, the 5 largest SCC are:\n",
    "# 615986: 434821,\n",
    "# 617403: 968,\n",
    "# 798411: 459,\n",
    "# 161539: 313,\n",
    "# 709991: 211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# N = 875714\n",
    "result = Kosarajus('1_SCC.txt', N = 875714)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
